version: "3.9"

services:
  llm-bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hpclab-llm-bot
    volumes:
      - ./src:/code/src
      - tf-data:/root/.cache
    ports:
      - "8080:8080"
      - "8000:8000"
    healthcheck:
      test: ["CMD-SHELL", "curl", "0.0.0.0:8080"]
      interval: 10s
      timeout: 30s
      retries: 5
    secrets:
      - vault-secrets.yml
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  dcgm_exporter:
    container_name: dcgm-exporter
    image: nvcr.io/nvidia/k8s/dcgm-exporter:2.4.6-2.6.10-ubuntu20.04
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    restart: always
    environment:
      - DCGM_EXPORTER_NO_HOSTNAME=1
    cap_add:
      - SYS_ADMIN
    ports:
      - "9400:9400"

  node-exporter:
    container_name: node-exporter
    image: prom/node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    hostname: exporter
    command:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --collector.filesystem.ignored-mount-points
      - ^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)
    ports:
      - 9100:9100
    restart: unless-stopped
    environment:
      TZ: "Europe/Moscow"
    networks:
      - default

secrets:
  vault-secrets.yml:
    file: ./vault-secrets.yml

volumes:
  tf-data:
